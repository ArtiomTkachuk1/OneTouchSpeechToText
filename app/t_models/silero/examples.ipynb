{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sCW-xvckaO8s"
   },
   "source": [
    "# Live Colab Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T09:39:54.418700Z",
     "start_time": "2020-09-12T09:39:54.415303Z"
    },
    "colab_type": "text",
    "id": "16gWjoEUXOhl"
   },
   "source": [
    "## Dependencies and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "jc7ZqfooYZnD"
   },
   "outputs": [],
   "source": [
    "#@title Install dependencies\n",
    "\n",
    "!pip install -q omegaconf\n",
    "!pip install -q torchaudio\n",
    "!pip install -q soundfile\n",
    "!pip install -q pydub\n",
    "\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "if not exists('silero-models'):\n",
    "  !git clone -q --depth 1 https://github.com/snakers4/silero-models\n",
    "\n",
    "%cd silero-models\n",
    "\n",
    "# silero imports\n",
    "import torch\n",
    "import random\n",
    "from glob import glob\n",
    "from omegaconf import OmegaConf\n",
    "from utils import (init_jit_model, \n",
    "                   split_into_batches,\n",
    "                   read_batch,\n",
    "                   prepare_model_input)\n",
    "from colab_utils import (record_audio,\n",
    "                         audio_bytes_to_np,\n",
    "                         upload_audio)\n",
    "\n",
    "device = torch.device('cpu')   # you can use any pytorch device\n",
    "models = OmegaConf.load('models.yml')\n",
    "\n",
    "# imports for uploading/recording\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio, display, clear_output\n",
    "\n",
    "\n",
    "# wav to text method\n",
    "def wav_to_text(f='test.wav'):\n",
    "  batch = read_batch([f])\n",
    "  input = prepare_model_input(batch, device=device)\n",
    "  output = model(input)\n",
    "  return decoder(output[0].cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6QIeg7XffsO"
   },
   "source": [
    "## Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "NJAOV1bbhEv0"
   },
   "outputs": [],
   "source": [
    "#@markdown { run: \"auto\" }\n",
    "\n",
    "language = \"English\" #@param [\"English\", \"German\", \"Spanish\"]\n",
    "\n",
    "print(language)\n",
    "if language == 'German':\n",
    "  model, decoder = init_jit_model(models.stt_models.de.latest.jit, device=device)\n",
    "elif language == \"Spanish\":\n",
    "  model, decoder = init_jit_model(models.stt_models.es.latest.jit, device=device)\n",
    "else:\n",
    "  model, decoder = init_jit_model(models.stt_models.en.latest.jit, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "QttWasy5hUd6"
   },
   "outputs": [],
   "source": [
    "#@markdown Either record audio from microphone or upload audio from file (.mp3 or .wav) { run: \"auto\" }\n",
    "\n",
    "record_or_upload = \"Record\" #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\n",
    "record_seconds =   4#@param {type:\"number\", min:1, max:10, step:1}\n",
    "sample_rate = 16000\n",
    "\n",
    "def _recognize(audio):\n",
    "  display(Audio(audio, rate=sample_rate, autoplay=True))\n",
    "  wavfile.write('test.wav', sample_rate, (32767*audio).numpy().astype(np.int16))\n",
    "  transcription = wav_to_text()\n",
    "  print('\\n\\nTRANSCRIPTION:\\n')\n",
    "  print(transcription)\n",
    "\n",
    "def _record_audio(b):\n",
    "  clear_output()\n",
    "  audio = record_audio(record_seconds)\n",
    "  _recognize(audio)\n",
    "\n",
    "def _upload_audio(b):\n",
    "  clear_output()\n",
    "  audio = upload_audio()\n",
    "  _recognize(audio)\n",
    "\n",
    "if record_or_upload == \"Record\":\n",
    "  button = widgets.Button(description=\"Record Speech\")\n",
    "  button.on_click(_record_audio)\n",
    "  display(button)\n",
    "else:\n",
    "  _upload_audio(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T13:31:58.954518Z",
     "start_time": "2020-09-11T13:31:58.952259Z"
    },
    "colab_type": "text",
    "id": "nMkcU8sDXOh8"
   },
   "source": [
    "# PyTorch Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "xj7emOprcPQ6"
   },
   "outputs": [],
   "source": [
    "#@title Install Dependencies\n",
    "\n",
    "# this assumes that you have a relevant version of PyTorch installed\n",
    "!pip install -q torchaudio\n",
    "!pip install -q omegaconf\n",
    "!pip install -q soundfile\n",
    "\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "if not exists('silero-models'):\n",
    "  !git clone -q --depth 1 https://github.com/snakers4/silero-models\n",
    "\n",
    "%cd silero-models\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from glob import glob\n",
    "from omegaconf import OmegaConf\n",
    "from utils import (init_jit_model, \n",
    "                   split_into_batches,\n",
    "                   read_batch,\n",
    "                   prepare_model_input)\n",
    "from IPython.display import display, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "PXEfylBwbAYI"
   },
   "outputs": [],
   "source": [
    "#@title Random English Validation Dataset (optional)\n",
    "\n",
    "if not exists('scottish_english_female'):\n",
    "  !wget http://www.openslr.org/resources/83/scottish_english_female.zip\n",
    "  !unzip -qq scottish_english_female.zip -d scottish_english_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "dwSIJ6bmbAzq"
   },
   "outputs": [],
   "source": [
    "#@title Random Spanish Validation Dataset (optional)\n",
    "\n",
    "if not exists('es_pr_female'):\n",
    "  !wget http://www.openslr.org/resources/74/es_pr_female.zip\n",
    "  !unzip -qq es_pr_female.zip -d es_pr_female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8r3DW7IgkJil"
   },
   "source": [
    "## Example cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T14:21:25.234818Z",
     "start_time": "2020-09-11T14:21:25.218179Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "GE0S5kmdXOiG"
   },
   "outputs": [],
   "source": [
    "models = OmegaConf.load('models.yml')  # all available models are listed in the yml file\n",
    "print(list(models.stt_models.keys()),\n",
    "      list(models.stt_models.en.keys()),\n",
    "      list(models.stt_models.en.latest.keys()),\n",
    "      models.stt_models.en.latest.jit)\n",
    "device = torch.device('cpu')   # you can use any pytorch device\n",
    "model, decoder = init_jit_model(models.stt_models.en.latest.jit, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T14:21:26.056045Z",
     "start_time": "2020-09-11T14:21:26.040771Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "GSUsZ7cqXOiL"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')   # you can use any pytorch device\n",
    "model, decoder = init_jit_model(models.stt_models.en.latest.jit, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T14:25:14.996913Z",
     "start_time": "2020-09-11T14:21:40.831866Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "paW8mugZXOiP"
   },
   "outputs": [],
   "source": [
    "# test_files = glob('path/to/your/file/*.opus')\n",
    "test_files = glob('scottish_english_female/*.wav')  # replace with your data\n",
    "batches = split_into_batches(test_files, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T13:57:09.061692Z",
     "start_time": "2020-09-11T13:57:08.992493Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "JryVNe5hXOiR"
   },
   "outputs": [],
   "source": [
    "# transcribe a set of files\n",
    "input = prepare_model_input(read_batch(random.sample(batches, k=1)[0]),\n",
    "                            device=device)\n",
    "output = model(input)\n",
    "for example in output:\n",
    "    print(decoder(example.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T14:38:32.972790Z",
     "start_time": "2020-09-11T14:38:31.605231Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "FgvdCQRSXOiY"
   },
   "outputs": [],
   "source": [
    "# listen to one file\n",
    "batch = read_batch(random.sample(batches, k=1)[0])\n",
    "input = prepare_model_input(batch,\n",
    "                            device=device)\n",
    "output = model(input)\n",
    "\n",
    "for i, example in enumerate(output):\n",
    "    print(decoder(example.cpu()))\n",
    "    display(Audio(batch[i], rate=16000))  # audio was resampled to 16kHz\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgoDrXPKXOih"
   },
   "source": [
    "# ONNX example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "Vu8nrog5dpqi"
   },
   "outputs": [],
   "source": [
    "#@title Install and Import Dependencies\n",
    "\n",
    "# this assumes that you have a relevant version of PyTorch installed\n",
    "!pip install -q torchaudio\n",
    "!pip install -q omegaconf\n",
    "!pip install -q soundfile\n",
    "!pip install -q onnx\n",
    "!pip install -q onnxruntime\n",
    "\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "if not exists('silero-models'):\n",
    "  !git clone -q --depth 1 https://github.com/snakers4/silero-models\n",
    "\n",
    "%cd silero-models\n",
    "\n",
    "import json\n",
    "import onnx\n",
    "import torch\n",
    "import random\n",
    "import tempfile\n",
    "import onnxruntime\n",
    "from glob import glob\n",
    "from omegaconf import OmegaConf\n",
    "from utils import (init_jit_model, Decoder, read_batch,\n",
    "                   split_into_batches, prepare_model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hx6PbiHxfGuA"
   },
   "source": [
    "## Example Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T14:14:24.015836Z",
     "start_time": "2020-09-11T14:14:23.999060Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "s7pSWy9lXOis"
   },
   "outputs": [],
   "source": [
    "models = OmegaConf.load('models.yml')  # all available models are listed in the yml file\n",
    "print(list(models.stt_models.en.latest))  # see which models are available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T14:15:01.939254Z",
     "start_time": "2020-09-11T14:14:25.969658Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8rCAeSAHXOi0"
   },
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile('wb', suffix='.json') as f:\n",
    "    torch.hub.download_url_to_file(models.stt_models.en.latest.labels,\n",
    "                               f.name,\n",
    "                               progress=True)\n",
    "    with open(f.name) as f:\n",
    "        labels = json.load(f)\n",
    "        decoder = Decoder(labels)\n",
    "\n",
    "with tempfile.NamedTemporaryFile('wb', suffix='.model') as f:\n",
    "    torch.hub.download_url_to_file(models.stt_models.en.latest.onnx,\n",
    "                                   f.name,\n",
    "                                   progress=True)\n",
    "    onnx_model = onnx.load(f.name)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    ort_session = onnxruntime.InferenceSession(f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T14:16:06.722402Z",
     "start_time": "2020-09-11T14:16:06.645751Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "kCZEm1UuXOi2"
   },
   "outputs": [],
   "source": [
    "# note that for now ONNX supports only batchless models, i.e. just samples\n",
    "# as it is mostly intended for porting the network elsewhere\n",
    "\n",
    "# test_files = glob('path/to/your/file/*.opus')\n",
    "test_files = glob('scottish_english_female/*.wav')  # replace with your data\n",
    "batches = split_into_batches(test_files, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T14:19:24.677767Z",
     "start_time": "2020-09-11T14:19:24.671730Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5go91lMUXOi4"
   },
   "outputs": [],
   "source": [
    "input = prepare_model_input(\n",
    "    read_batch(\n",
    "        random.sample(batches, k=1)[0]\n",
    "    )\n",
    ").detach().cpu().numpy()[0]\n",
    "\n",
    "ort_inputs = {'input': input}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "decoded = decoder(torch.Tensor(ort_outs[0]))\n",
    "print(decoded)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "colab_examples.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
